{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![transformer模型](img/transformer.png) \n",
    "<center><big>transformer模型</big></center>\n",
    "\n",
    "![transformer-encoder模型](img/transformer-encoder.png)\n",
    "<center><big>transformer-encoder模型</big></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "利用transformer左半部分的transformer-encoder作意图分类\n",
    "直接将encoder的输出接一个全连接层来作分类模型使用\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchtext import data,datasets\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "from torchtext.vocab import Vectors\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "intent_classification_path = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "# 训练数据路径\n",
    "train_data = os.path.join(intent_classification_path,'classification_data/knowledge_point_qa_data.csv')\n",
    "# 读取数据\n",
    "train_data = pd.read_csv(train_data)\n",
    "# 按字分    \n",
    "tokenize =lambda x: x.split(' ')\n",
    "\n",
    "TEXT = data.Field(\n",
    "                    sequential=True,\n",
    "                    tokenize=tokenize,\n",
    "                    lower=True,\n",
    "                    use_vocab=True,\n",
    "                    pad_token='<pad>',\n",
    "                    unk_token='<unk>',\n",
    "                    batch_first=True,\n",
    "                    fix_length=20)\n",
    "\n",
    "LABEL = data.Field(\n",
    "                    sequential=False,\n",
    "                    use_vocab=False)\n",
    "\n",
    "# 获取训练或测试数据集\n",
    "def get_dataset(csv_data, text_field, label_field, test=False):\n",
    "    fields = [('id', None), ('text', text_field), ('label', label_field)]\n",
    "    examples = []\n",
    "    if test: #测试集，不加载label\n",
    "        for text in csv_data['text']:\n",
    "            examples.append(data.Example.fromlist([None, text, None], fields))\n",
    "    else: # 训练集\n",
    "        for text, label in zip(csv_data['text'], csv_data['label']):\n",
    "            examples.append(data.Example.fromlist([None, text, label], fields))\n",
    "    return examples, fields\n",
    "\n",
    "train_examples,train_fields = get_dataset(train_data, TEXT, LABEL)\n",
    "\n",
    "train = data.Dataset(train_examples, train_fields)\n",
    "# 预训练数据\n",
    "#pretrained_embedding = os.path.join(os.getcwd(), 'sgns.sogou.char')\n",
    "#vectors = Vectors(name=pretrained_embedding)\n",
    "# 构建词典\n",
    "#TEXT.build_vocab(train, min_freq=1, vectors = vectors)\n",
    "\n",
    "TEXT.build_vocab(train, min_freq=1)\n",
    "words_path = os.path.join(os.getcwd(), 'words.pkl')\n",
    "with open(words_path, 'wb') as f_words:\n",
    "    pickle.dump(TEXT.vocab, f_words)\n",
    "    \n",
    "BATCH_SIZE = 163\n",
    "# 构建迭代器\n",
    "train_iter = BucketIterator(\n",
    "                            dataset=train,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True,\n",
    "                            sort_within_batch=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "pad_index = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "print(pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    1.输入是序列中token的embedding与位置embedding\n",
    "    2.token的embedding与其位置embedding相加，得到一个vector(这个向量融合了token与position信息)\n",
    "    3.在2之前，token的embedding乘上一个scale(防止点积变大，造成梯度过小)向量[sqrt(emb_dim)]，这个假设为了减少embedding中的变化，没有这个scale，很难稳定的去训练model。\n",
    "    4.加入dropout\n",
    "    5.通过N个encoder layer，得到Z。此输出Z被传入一个全连接层作分类。\n",
    "    src_mask对于非<pad>值为1,<pad>为0。为了计算attention而遮挡<pad>这个无意义的token。与source 句子shape一致。\n",
    "'''\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, emb_dim, n_layers, n_heads, pf_dim, dropout, position_length, pad_idx):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        \n",
    "        self.pad_idx = pad_idx\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([emb_dim])).to(DEVICE)\n",
    "\n",
    "        # 词的embedding\n",
    "        self.token_embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        # 对词的位置进行embedding\n",
    "        self.position_embedding = nn.Embedding(position_length, emb_dim)\n",
    "        # encoder层，有几个encoder层，每个encoder有几个head\n",
    "        self.layers = nn.ModuleList([EncoderLayer(emb_dim, n_heads, pf_dim, dropout) for _ in range(n_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(emb_dim, output_dim)\n",
    "\n",
    "    def mask_src_mask(self, src):\n",
    "        # src=[batch_size, src_len]\n",
    "\n",
    "        # src_mask=[batch_size, 1, 1, src_len]\n",
    "        src_mask = (src != self.pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "    \n",
    "    def forward(self, src):\n",
    "        # src=[batch_size, seq_len]\n",
    "        # src_mask=[batch_size, 1, 1, seq_len]\n",
    "        src_mask = self.mask_src_mask(src)\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "\n",
    "        # 构建位置tensor -> [batch_size, seq_len]，位置序号从(0)开始到(src_len-1)\n",
    "        position = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(DEVICE)\n",
    "\n",
    "        # 对词和其位置进行embedding -> [batch_size,seq_len,embdim]\n",
    "        token_embeded = self.token_embedding(src) * self.scale\n",
    "        position_embeded = self.position_embedding(position)\n",
    "\n",
    "        # 对词和其位置的embedding进行按元素加和 -> [batch_size, seq_len, embdim]\n",
    "        src = self.dropout(token_embeded + position_embeded)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask)\n",
    "\n",
    "        # [batch_size, seq_len, emb_dim] -> [batch_size, output_dim]\n",
    "        src = src.permute(0, 2, 1)\n",
    "        src = torch.sum(src, dim=-1)\n",
    "        src = self.fc(src)\n",
    "        return src\n",
    "\n",
    "'''\n",
    "encoder layers：\n",
    "    1.将src与src_mask传入多头attention层(multi-head attention)\n",
    "    2.dropout\n",
    "    3.使用残差连接后传入layer-norm层(输入+输出后送入norm)后得到的输出\n",
    "    4.输出通过前馈网络feedforward层\n",
    "    5.dropout\n",
    "    6.一个残差连接后传入layer-norm层后得到的输出喂给下一层\n",
    "    注意：\n",
    "        layer之间不共享参数\n",
    "        多头注意力层用到的是多个自注意力层self-attention\n",
    "'''\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, emb_dim, n_heads, pf_dim, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        # 注意力层后的layernorm\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(emb_dim)\n",
    "        # 前馈网络层后的layernorm\n",
    "        self.ff_layer_norm = nn.LayerNorm(emb_dim)\n",
    "        # 多头注意力层\n",
    "        self.self_attention = MultiHeadAttentionLayer(emb_dim, n_heads, dropout)\n",
    "        # 前馈层\n",
    "        self.feedforward = FeedforwardLayer(emb_dim, pf_dim, dropout)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        #src=[batch_size, seq_len, emb_dim]\n",
    "        #src_mask=[batch_size, 1, 1, seq_len]\n",
    "\n",
    "        # self-attention\n",
    "        # _src=[batch size, query_len, emb_dim]\n",
    "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
    "\n",
    "        # dropout, 残差连接以及layer-norm\n",
    "        # src=[batch_size, seq_len, emb_dim]\n",
    "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "\n",
    "        # 前馈网络\n",
    "        # _src=[batch_size, seq_len, emb_dim]\n",
    "        _src = self.feedforward(src)\n",
    "\n",
    "        # dropout, 残差连接以及layer-norm\n",
    "        # src=[batch_size, seq_len, emb_dim]\n",
    "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
    "\n",
    "        return src\n",
    "'''\n",
    "多头注意力层的计算:\n",
    "    1.q,k,v的计算是通过线性层fc_q,fc_k,fc_v\n",
    "    2.对query,key,value的emb_dim split成n_heads\n",
    "    3.通过计算Q*K/scale计算energy\n",
    "    4.利用mask遮掩不需要关注的token\n",
    "    5.利用softmax与dropout\n",
    "    6.5的结果与V矩阵相乘\n",
    "    7.最后通过一个前馈fc_o输出结果\n",
    "注意:Q,K,V的长度一致\n",
    "'''\n",
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    def __init__(self, emb_dim, n_heads, dropout):\n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "        assert emb_dim % n_heads == 0\n",
    "        self.emb_dim = emb_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = emb_dim//n_heads\n",
    "\n",
    "        self.fc_q = nn.Linear(emb_dim, emb_dim)\n",
    "        self.fc_k = nn.Linear(emb_dim, emb_dim)\n",
    "        self.fc_v = nn.Linear(emb_dim, emb_dim)\n",
    "\n",
    "        self.fc_o = nn.Linear(emb_dim, emb_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(DEVICE)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # query=[batch_size, query_len, emb_dim]\n",
    "        # key=[batch_size, key_len, emb_dim]\n",
    "        # value=[batch_size, value_len, emb_dim]\n",
    "        batch_size = query.shape[0]\n",
    "\n",
    "        # Q=[batch_size, query_len, emb_dim]\n",
    "        # K=[batch_size, key_len, emb_dim]\n",
    "        # V=[batch_size, value_len, emb_dim]\n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "\n",
    "        '''\n",
    "        view与reshape的异同：\n",
    "        \n",
    "        torch的view()与reshape()方法都可以用来重塑tensor的shape，区别就是使用的条件不一样。view()方法只适用于满足连续性条件的tensor，并且该操作不会开辟新的内存空间，\n",
    "        只是产生了对原存储空间的一个新别称和引用，返回值是视图。而reshape()方法的返回值既可以是视图，也可以是副本，当满足连续性条件时返回view，\n",
    "        否则返回副本[ 此时等价于先调用contiguous()方法在使用view() ]。因此当不确能否使用view时，可以使用reshape。如果只是想简单地重塑一个tensor的shape，\n",
    "        那么就是用reshape，但是如果需要考虑内存的开销而且要确保重塑后的tensor与之前的tensor共享存储空间，那就使用view()。\n",
    "        '''\n",
    "\n",
    "        # Q=[batch_size, n_heads, query_len, head_dim]\n",
    "        # K=[batch_size, n_heads, key_len, head_dim]\n",
    "        # V=[batch_size, n_heads, value_len, head_dim]\n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "        # 注意力打分矩阵 [batch_size, n_heads, query_len, head_dim] * [batch_size, n_heads, head_dim, key_len] = [batch_size, n_heads, query_len, key_len]\n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        # [batch_size, n_heads, query_len, key_len]\n",
    "        attention = torch.softmax(energy , dim = -1)\n",
    "\n",
    "        # [batch_size, n_heads, query_len, key_len]*[batch_size, n_heads, value_len, head_dim]=[batch_size, n_heads, query_len, head_dim]\n",
    "        x = torch.matmul(self.dropout(attention), V)\n",
    "\n",
    "        # [batch_size, query_len, n_heads, head_dim]\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # [batch_size, query_len, emb_dim]\n",
    "        x = x.view(batch_size, -1, self.emb_dim)\n",
    "\n",
    "        # [batch_size, query_len, emb_dim]\n",
    "        x = self.fc_o(x)\n",
    "\n",
    "        return x, attention\n",
    "\n",
    "'''\n",
    "前馈层\n",
    "'''\n",
    "class FeedforwardLayer(nn.Module):\n",
    "    def __init__(self, emb_dim, pf_dim, dropout):\n",
    "        super(FeedforwardLayer, self).__init__()\n",
    "        self.fc_1 = nn.Linear(emb_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, emb_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x=[batch_size, seq_len, emb_dim]\n",
    "\n",
    "        # x=[batch_size, seq_len, pf_dim]\n",
    "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
    "\n",
    "        # x=[batch_size, seq_len, emb_dim]\n",
    "        x = self.fc_2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter [10/300], Loss: 11.2852\n",
      "iter [20/300], Loss: 1.6953\n",
      "iter [30/300], Loss: 0.4578\n",
      "iter [40/300], Loss: 0.3103\n",
      "iter [50/300], Loss: 0.0917\n",
      "iter [60/300], Loss: 0.0899\n",
      "iter [70/300], Loss: 0.0558\n",
      "iter [80/300], Loss: 0.0854\n",
      "iter [90/300], Loss: 0.1266\n",
      "iter [100/300], Loss: 0.0453\n",
      "iter [110/300], Loss: 0.0878\n",
      "iter [120/300], Loss: 0.0980\n",
      "iter [130/300], Loss: 0.0106\n",
      "iter [140/300], Loss: 0.1008\n",
      "iter [150/300], Loss: 0.0306\n",
      "iter [160/300], Loss: 0.1012\n",
      "iter [170/300], Loss: 0.0547\n",
      "iter [180/300], Loss: 0.1332\n",
      "iter [190/300], Loss: 0.0677\n",
      "iter [200/300], Loss: 0.0225\n",
      "iter [210/300], Loss: 0.0558\n",
      "iter [220/300], Loss: 0.0771\n",
      "iter [230/300], Loss: 0.0459\n",
      "iter [240/300], Loss: 0.1319\n",
      "iter [250/300], Loss: 0.0990\n",
      "iter [260/300], Loss: 0.0625\n",
      "iter [270/300], Loss: 0.0545\n",
      "iter [280/300], Loss: 0.0503\n",
      "iter [290/300], Loss: 0.0845\n",
      "iter [300/300], Loss: 0.0047\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(os.getcwd()+'/log', comment='transformer-encoder')\n",
    "\n",
    "# 训练\n",
    "input_dim = len(TEXT.vocab) \n",
    "output_dim = 9\n",
    "emb_dim = 256\n",
    "n_layers = 3\n",
    "n_heads = 8\n",
    "pf_dim = 512\n",
    "dropout = 0.5\n",
    "position_length = 20\n",
    "\n",
    "# <pad>\n",
    "pad_index = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "# 构建model\n",
    "model = TransformerEncoder(input_dim, output_dim, emb_dim, n_layers, n_heads, pf_dim, dropout, position_length, pad_index).to(DEVICE)\n",
    "# 利用预训练模型初始化embedding，requires_grad=True，可以fine-tune\n",
    "# model.embedding.weight.data.copy_(TEXT.vocab.vectors)\n",
    "# 训练模式\n",
    "model.train()\n",
    "# 优化和损失\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001, weight_decay=0.01)\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=0.001, momentum=0.9, nesterov=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with writer:\n",
    "    for iter in range(300):\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            train_text = batch.text\n",
    "            train_label = batch.label\n",
    "            train_text = train_text.to(DEVICE)\n",
    "            train_label = train_label.to(DEVICE)\n",
    "            out = model(train_text)\n",
    "            loss = criterion(out, train_label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (iter+1) % 10 == 0:\n",
    "                    print ('iter [{}/{}], Loss: {:.4f}'.format(iter+1, 300, loss.item()))\n",
    "            #writer.add_graph(model, input_to_model=train_text,verbose=False)\n",
    "            writer.add_scalar('loss',loss.item(),global_step=iter+1)\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "            \n",
    "model_path = os.path.join(os.getcwd(), \"model.h5\")\n",
    "torch.save(model.state_dict(), model_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![transformer-encoder模型](img/loss.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
